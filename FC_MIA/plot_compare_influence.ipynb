{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset_path = './models_all_checkpoints/experiment_1/logs'\n",
    "logdir = '../log_nngp_vs_nn'\n",
    "\n",
    "whole_dataset = np.load(f'{dataset_path}/total_dataset.npy')\n",
    "whole_labels = np.load(f'{dataset_path}/total_labels.npy')\n",
    "df_nn = pd.read_csv('../log_nngp_vs_nn/log_nn/nn.csv')\n",
    "df_nngp = pd.read_csv('../log_nngp_vs_nn/log_nngp/nngp.csv')\n",
    "assert(sum(list(abs(df_nn['differ_idx'] - df_nngp['differ_idx'])))==0)\n",
    "differ_indices = list(df_nn['differ_idx'])\n",
    "diff_nn = list(df_nn['diff'])\n",
    "diff_nn_std = list(df_nn['diff_std'])\n",
    "mse_nngp = list(df_nngp['mse'])\n",
    "\n",
    "import torch\n",
    "def to_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "h_message = ''\n",
    "\n",
    "def continuous_seq(*args, **kwargs):\n",
    "    '''\n",
    "    >>> return a float to float mapping\n",
    "    '''\n",
    "    name = kwargs['name']\n",
    "    max_v = kwargs['max'] if 'max' in kwargs else np.inf\n",
    "    min_v = kwargs['min'] if 'min' in kwargs else -np.inf\n",
    "\n",
    "    if name.lower() in ['h', 'help']:\n",
    "        print(h_message)\n",
    "        exit(0)\n",
    "    elif name.lower() in ['constant',]:\n",
    "        start_v = float(kwargs['start_v'])\n",
    "        return lambda x: np.clip(start_v, a_min = min_v, a_max = max_v)\n",
    "    elif name.lower() in ['linear',]:\n",
    "        start_v = float(kwargs['start_v'])\n",
    "        slope = float(kwargs['slope'])\n",
    "        return lambda x: np.clip(start_v + x * slope, a_min = min_v, a_max = max_v)\n",
    "    elif name.lower() in ['exp, exponential',]:\n",
    "        start_v = float(kwargs['start_v'])\n",
    "        power = float(kwargs['power'])\n",
    "        interval = int(kwargs['interval']) if 'interval' in kwargs else 1\n",
    "        return lambda x: np.clip(start_v * power ** (x / float(interval)), a_min = min_v, a_max = max_v)\n",
    "    elif name.lower() in ['jump',]:\n",
    "        start_v = float(kwargs['start_v'])\n",
    "        power = float(kwargs['power'])\n",
    "        min_jump_pt = int(kwargs['min_jump_pt'])\n",
    "        jump_freq = int(kwargs['jump_freq'])\n",
    "        return lambda x: np.clip(start_v * power ** (max(x - min_jump_pt + jump_freq, 0) // jump_freq), a_min = min_v, a_max = max_v)\n",
    "    else:\n",
    "        raise ValueError('Unrecognized name: %s'%name)\n",
    "\n",
    "lr_schedule = {'name': 'jump', 'start_v': 0.001, 'power' : 0.1, 'min_jump_pt': 25, 'jump_freq': 10}\n",
    "lr_func = continuous_seq(**lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "tracein_estimates = []\n",
    "for differ_idx in differ_indices:\n",
    "  data = whole_dataset[differ_idx - 1: differ_idx]\n",
    "  labels = whole_labels[differ_idx - 1: differ_idx]\n",
    "\n",
    "\n",
    "  traceinfluence = 0\n",
    "  for i in range(50):\n",
    "    epoch = i + 1\n",
    "    out_path = dataset_path.replace('logs','models')\n",
    "    temp_model = torch.load(f'{out_path}/model-{epoch}.pkl')\n",
    "    temp_model.train()\n",
    "\n",
    "    differ_preds = temp_model(to_cuda(torch.from_numpy(data).float()))\n",
    "    loss_temp = nn.CrossEntropyLoss()(differ_preds, to_cuda(torch.LongTensor(labels)))\n",
    "    loss_temp.backward()\n",
    "    grad_vec = 0\n",
    "    for p in temp_model.parameters():\n",
    "      grad_vec = (p.grad.data **2).sum() + grad_vec\n",
    "      p.grad.data.zero_()\n",
    "    lr_this_epoch = lr_func(epoch)\n",
    "    # print(f\"grad: {grad_vec.cpu().numpy()}, lr: {lr_this_epoch}\")\n",
    "    traceinfluence = traceinfluence + grad_vec.cpu().numpy() * lr_this_epoch\n",
    "  tracein_estimates.append(traceinfluence)\n",
    "\n",
    "print(tracein_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_influence import LiSSAInfluenceModule\n",
    "from utils.dataset import *\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_influence import BaseObjective\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "valid_ratio = 0\n",
    "out_path = dataset_path.replace('logs','models')\n",
    "damp=0.001\n",
    "repeat=5\n",
    "depth=50 #2000\n",
    "scale=500\n",
    "\n",
    "class MyObjective(BaseObjective):\n",
    "\n",
    "    def train_outputs(self, model, batch):\n",
    "        return model(batch[0])\n",
    "\n",
    "    def train_loss_on_outputs(self, outputs, batch):\n",
    "        return F.cross_entropy(outputs, batch[1])  # mean reduction required\n",
    "\n",
    "    def train_regularization(self, params):\n",
    "        return 0.0\n",
    "\n",
    "    # training loss by default taken to be \n",
    "    # train_loss_on_outputs + train_regularization\n",
    "\n",
    "    def test_loss(self, model, params, batch):\n",
    "        return F.cross_entropy(model(batch[0]), batch[1])  # no regularization in test loss\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader, classes = cifar10(batch_size=batch_size, valid_ratio=valid_ratio)\n",
    "\n",
    "model = torch.load(f'{out_path}/model-best.pkl')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "module = LiSSAInfluenceModule(\n",
    "    model=model,\n",
    "    objective=MyObjective(),  \n",
    "    train_loader=train_loader,\n",
    "    test_loader=train_loader, #Since we want to calculate self-influence\n",
    "    device=device,\n",
    "    damp=damp,\n",
    "    repeat=repeat,\n",
    "    depth=depth,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "inf_list = []\n",
    "for differ_idx in differ_indices:\n",
    "    # influence scores of training points on themselves\n",
    "    scores = module.influences([differ_idx-1], [differ_idx-1])\n",
    "    print(scores)\n",
    "    inf_list.append(scores.item())\n",
    "\n",
    "print(inf_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "save_df = pd.DataFrame({'diff_nn': diff_nn, 'diff_nn_std': diff_nn_std, 'mse_nngp':  mse_nngp, 'tracin': tracein_estimates, 'inf_func': inf_list})\n",
    "save_df.to_csv(f'{logdir}/compare_influence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns; \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (4,2.8))\n",
    "ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "y = (np.sqrt(diff_nn) - min(np.sqrt(diff_nn)))/(max(np.sqrt(diff_nn)) - min(np.sqrt(diff_nn)))\n",
    "x = (np.array(inf_list) - min(inf_list))/(max(inf_list) - min(inf_list))\n",
    "sns.regplot(x=x, y=y, label=f'Inf fun (Koh & Liang) (r={pearsonr(x, y).statistic:.2f}, p={pearsonr(x, y).pvalue:.2g})', marker = '+', line_kws={\"ls\":':'})\n",
    "x = (np.array(tracein_estimates) - min(tracein_estimates))/(max(tracein_estimates) - min(tracein_estimates))\n",
    "sns.regplot(x=x, y=y, label=f'TracIn (Pruti et al.) (r={pearsonr(x, y).statistic:.2f}, p={pearsonr(x, y).pvalue:.2g})', marker = '+', line_kws={\"ls\":':'})\n",
    "x = (np.sqrt(mse_nngp) - min(np.sqrt(mse_nngp)))/(max(np.sqrt(mse_nngp)) - min(np.sqrt(mse_nngp)))\n",
    "sns.regplot(x=x, y=y, label=r'$\\sqrt{Mean\\ distance\\ LOOD}$' + f'(r={pearsonr(x, y).statistic:.2f}, p={pearsonr(x, y).pvalue:.2g})', marker = '+', line_kws={\"ls\":':'})\n",
    "\n",
    "plt.ylabel('NN l2 prediction difference', fontsize = 12)\n",
    "plt.xlabel('Estimate score by various methods', fontsize = 12)\n",
    "plt.legend(fontsize = 12, loc = 'upper center', bbox_to_anchor=(0.45, 1.54))\n",
    "plt.savefig(f'{logdir}/compare_influence.png', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022_myGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
